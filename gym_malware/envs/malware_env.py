# encoding=utf-8
import hashlib
import os
import random
from collections import OrderedDict

import gym
from gym import spaces

from gym_malware.envs.controls import action as manipulate
from gym_malware.envs.utils import interface, pefeatures, reward

ACTION_LOOKUP = {i: act for i, act in enumerate(
    manipulate.ACTION_TABLE.keys())}

# change this to function to the AV engine to attack
# function should be of the form
# def label_function( bytez ):
#    # returns 0.0 if benign else 1.0 if malware
label_function = reward.label_function


# an environment must define its
# observation space and action space
# and have at least two methods: reset and step.

# * env.reset will reset the environment to the initial state and return the initial observation.
# * env.step will execute a given action, move to the next state and return four values:
#   a next observation
#   a scalar reward
#   a boolean value indicating whether the current state is terminal or not
#   additional information
# * env.render will render the current state.
class MalwareEnv(gym.Env):
    metadata = {'render.modes': ['human']}

    def __init__(self, sha256list, random_sample=True, maxturns=10, output_path='evaded/blackbox/', cache=True,
                 test=False):
        self.total_turn = 0
        self.episode = -1  # 共训练了多少轮
        self.cache = cache
        self.available_sha256 = sha256list
        self.action_space = spaces.Discrete(len(ACTION_LOOKUP))
        self.maxturns = maxturns
        self.feature_extractor = pefeatures.PEFeatureExtractor()
        self.random_sample = random_sample
        self.sample_iteration_index = 0
        self.test = test
        self.output_path = os.path.join(
            os.path.dirname(
                os.path.dirname(
                    os.path.dirname(
                        os.path.abspath(__file__)))), output_path)
        if not os.path.exists(output_path):
            os.makedirs(output_path)

        self.history = OrderedDict()

        self.samples = {}
        self.reward_engine = reward.ClamAV()

        if self.cache:
            for sha256 in self.available_sha256:
                try:
                    self.samples[sha256] = interface.fetch_file(sha256, self.test)
                except interface.FileRetrievalFailure:
                    print("failed fetching file")
                    continue  # try a new sha256...this one can't be retrieved from storage

        self._reset()

    def _step(self, action_index):
        reward = 0
        self.total_turn += 1
        self.turns += 1
        # a_t
        self._take_action(action_index)  # update self.bytez

        # 调用杀毒软件 get reward R_(t+1)
        try:
            self.label = label_function(self.reward_engine, self.bytez)
        except interface.ClassificationFailure:
            print("Failed to classify file")
            episode_over = True
        else:
            # 获取样本当前的状态 S_(t+1)
            # TODO
            self.observation_space = self.feature_extractor.extract(self.bytez)

            if self.label == 0:
                # we win!
                reward = 10.0  # !! a strong reward
                print("success!")
                episode_over = True
                self.history[self.sha256]['evaded'] = True

                # store sample to output directory
                if self.test:
                    m = hashlib.sha256()
                    m.update(self.bytez)
                    sha256 = m.hexdigest()
                    self.history[self.sha256]['evaded_sha256'] = sha256

                    with open(os.path.join(self.output_path, sha256), 'wb') as outfile:
                        outfile.write(self.bytez)
                    with open("test_log.txt", 'a+') as f:
                        f.write("action is {}\n".format(action_index))
                        f.write("end\n")

            elif self.turns >= self.maxturns:
                # out of turns :(
                reward = 0.0
                episode_over = True
                if self.test:
                    with open("test_log.txt", 'a+') as f:
                        f.write("action is {}\n".format(action_index))
                        f.write("end\n")
            else:
                reward = 0.0
                episode_over = False
                if self.test:
                    with open("test_log.txt", 'a+') as f:
                        f.write("action is {}\n".format(action_index))

        # S_(t+1), R_(t+1), done, info
        return self.observation_space, reward, episode_over, {}

    def _take_action(self, action_index):
        assert action_index < len(ACTION_LOOKUP)
        action = ACTION_LOOKUP[action_index]
        self.history[self.sha256]['actions'].append(action)
        self.bytez = bytes(manipulate.modify_without_breaking(self.bytez, [action]))
        # print("turns {} : {}".format(self.turns, action))


    def _reset(self):
        self.turns = 0
        self.episode += 1
        while True:
            # get the new environment
            if self.random_sample:
                self.sha256 = random.choice(self.available_sha256)
            else:  # draw a sample at random
                self.sha256 = self.available_sha256[self.sample_iteration_index % len(self.available_sha256)]
                self.sample_iteration_index += 1

            self.history[self.sha256] = {'actions': [], 'evaded': False}
            if self.cache:
                self.bytez = self.samples[self.sha256]
            else:
                try:
                    self.bytez = interface.fetch_file(self.sha256, self.test)
                except interface.FileRetrievalFailure:
                    print("failed fetching file")
                    continue  # try a new sha256...this one can't be retrieved from storage

            original_label = label_function(self.reward_engine, self.bytez)
            if original_label == 0:
                # skip this one, it's already benign, and the graduation_agent will learn nothing
                continue

            self.tips = ' ' if not self.test else 'test '

            if self.episode > 0:
                print("--------------------------------------------------------------------------------")
                print("{}episode {} select training sample: {}".format(self.tips, self.episode, self.sha256))
                print("--------------------------------------------------------------------------------")

            self.observation_space = self.feature_extractor.extract(self.bytez)

            break  # we're done here

        return self.observation_space